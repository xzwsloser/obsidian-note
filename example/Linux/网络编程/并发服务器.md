# 高并发服务器
- 高并法服务器分析:
![alt text](../img/Screenshot_20240831_110408_tv.danmaku.bilibilihd.jpg)
## 多进程并发服务器
### 分析
- 一个服务器进程中,首先利用 `socket()` 创建一个 `lfd` ,当有客户端尝试连接的时候,这一个 `lfd` 就会结合 `accept` 函数创建一个 `cfd` ,利用这一个 `cfd` 和服务器端进行通信,并且之后来了更多的客户端尝试连接,`lfd` 也只有一个,而是不断创建 `cfd`
- 实现思路分析:
  1. `socket()` 创建,监听套接字 `lfd`
  2. `Bind()`  绑定地址结构 `struct sockaddr_in`
  3. `Listen()`
  4. 循环利用 `accept` 进行接受,接受之后 `fork()` 子进程
  5. **子进程处理业务逻辑(注意子进程中需要关闭用于建立连接的套接字)**
  6. **父进程继续监听客户端的连接,同时关闭用于和客户端进行通信的套接字**
  7. 父进程可以注册捕捉信号函数从而回收子进程
### 实现
```c
#include "wrap.h"
#include<ctype.h>
#include<signal.h>
#include<sys/wait.h>
#define SERVER_PORT 10086
// 利用信号进行子进程的回收
void resource_handler(int signal)
{
    // 循环进行子进程的回收
    int n ;
    while((n = waitpid(-1 , NULL , 0)) != -1){
        // 进行挥手
        printf("child whose pid is %d is resouced ! \n" , n);
    }
}
int main()
{
    // 利用进程实现的并发服务器
    // 1. 利用 Socket 获得 lfd
    int lfd , cfd;
    int pid;
    char buf[BUFSIZ] , client_IP[BUFSIZ]; // 表示读写使用的缓冲区
    lfd = Socket(AF_INET , SOCK_STREAM , 0);
    // 2. 利用 bind 绑定 IP 和 port
    struct sockaddr_in addr;
    addr.sin_family = AF_INET;
    addr.sin_addr.s_addr = htonl(INADDR_ANY);
    addr.sin_port = htons(SERVER_PORT);
    Bind(lfd , (struct sockaddr*)&addr , sizeof(addr));
    // 3. 利用 Listen 设置最大监听数量
    Listen(lfd , 128);
    // 4. 循环使用 accept 进行接受
    struct sockaddr_in client_addr;
    socklen_t client_addr_len = sizeof(client_addr);
    // 进行信号的屏蔽
    sigset_t sig;
    sigemptyset(&sig);
    sigaddset(&sig , SIGCHLD);
    sigprocmask(SIG_BLOCK , &sig , NULL);
    printf("等待客户端连接 ... \n");
    while(1){
        cfd = Accept(lfd , (struct sockaddr*)& client_addr , &client_addr_len);
        // fork函数调用
        pid = fork();
        // 开始判断操作
        if(pid == 0){
            // 子进程
            printf("连接到客户端== addr: %s , port: %d \n" , inet_ntop(AF_INET , (void*)&(client_addr.sin_addr.s_addr) , client_IP , client_addr_len) , ntohs(client_addr.sin_port));
            while(1){
                // 读取信息
                int n = read(cfd , buf , sizeof(buf));
                // 进行大小写转换
                if(n > 0){  
                    for(int i = 0 ; i < n ; i ++){
                        buf[i] = toupper(buf[i]);
                    }
                    // 写回去
                    write(cfd , buf , n);
                } else if (n == 0){
                    break;
                } else if(n == -1){
                    perror("read from socket failed !");
                    exit(1);
                }
            }
            close(cfd);
        } else if(pid > 0){
            // 父进程
            // 注册行为
            struct sigaction act;
            act.sa_handler = resource_handler;
            act.sa_flags = 0;
            sigemptyset(&act.sa_mask);
            sigaction(SIGCHLD , &act , NULL);
            // 取消阻塞
            sigset_t cancel_sig;
            sigemptyset(&cancel_sig);
            sigaddset(&cancel_sig , SIGCHLD);
            sigprocmask(SIG_UNBLOCK , &cancel_sig , NULL);
            close(cfd);
            continue;
        }
    }  
        close(lfd); 
}
```
## 多线程并发服务器
- 分析:
  1. `Socket()`创建套接字
  
  2. `Bind()`
  
  3. `Listen()`
  
  4. 接受请求,同时创建子线程
  
  5. 同时调用`pthread_detact`分离子线程让子线程被系统回收
  
  6. 如果还是需要使用 `pthread_join` 进行线程的回收,就可以创建一个子线程来回收其他的子线程
  
     **注意这里线程之前共享文件描述符表(其实线程就是栈和寄存器的集合),所以如果在任何一个线程中关闭某一个文件描述符号都会都是之后的负责读写的线程受到影响**
### 实现
- 多线程变成服务器实现:
- 为什么这里不可以使用值传递的方式进行参数传递,这是由于`void*`只会占用 `8` 个字节,但是需要的结构体大小比较大
```c
#include "wrap.h"
#include<pthread.h>
#include<ctype.h>
#define SREVER_PORT 18001
#define MAX_SIZE 128
struct client_info{
    struct sockaddr_in client_addr;
    int conn_fd;
};
struct client_info clients[256]; // 记录客户端的信息
pthread_t thread_to_resource[128];
char client_Buf[BUFSIZ];
void* client_handler(void* arg)
{
    struct client_info* client_addr_info = (struct client_info*)arg;
    char buf[BUFSIZ];    
    printf("连接到客户端:  %s:%d \n" , inet_ntop(AF_INET , (void*)&(client_addr_info -> client_addr.sin_addr.s_addr), client_Buf , sizeof(client_Buf)) , ntohs(client_addr_info -> client_addr.sin_port));
    int n;
    while(1){
        // 接受数据
        n = read(client_addr_info -> conn_fd , buf , sizeof(buf));
        if(n == -1){
            perror("read from socket failed !");
            pthread_exit(NULL);
        } else if(n > 0){
            for(int i = 0 ; i < n ; i ++){
                buf[i] = toupper(buf[i]);
            }
            write(client_addr_info -> conn_fd , buf , n);
        } else if (n == 0){
            break;
        }
    }
    close(client_addr_info -> conn_fd);
    return NULL;
}
// 回收线程
void* thread_handler(void* arg)
{
    int i = 0;
    int wpid;
    while(1){
        if(thread_to_resource[i] != 0){
            wpid = pthread_join(thread_to_resource[i] , NULL);
            printf("Successfully resource thread pid = %d \n" , thread_to_resource[i]);
            thread_to_resource[i] = 0;
        }
        i = (i + 1) % MAX_SIZE;
    }
    return NULL;
}
int main()
{
    pthread_t pid;
    int lfd , cfd;
    // 1. 利用 Socket 获取 lfd
    lfd = Socket(AF_INET , SOCK_STREAM , 0);
    // 2. 利用 Bind 进行 IP 地址和 port 的绑定
    struct sockaddr_in server_addr;
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    server_addr.sin_port = htons(SREVER_PORT);
    server_addr.sin_family = AF_INET;
    Bind(lfd , (struct sockaddr*)& server_addr , sizeof(server_addr));
    // 3. 利用 Listen 设置最大监听数量
    Listen(lfd , 128);
    // 4. 利用 Accept 函数循环接受结果
    int i = 0;
    struct sockaddr_in client_addr;
    socklen_t client_addr_len = sizeof(client_addr);
    while(1){
        // 封装信息
        cfd = Accept(lfd , (struct sockaddr*)&client_addr , &client_addr_len);
        clients[i].client_addr = client_addr;
        clients[i].conn_fd = cfd;
        // 创建子线程
        pthread_create(&pid , NULL , client_handler , (void*)&clients[i]);
        thread_to_resource[i] = pid; // 进行回收
        if(i == 0){
            // 开启回收线程
            pthread_create(&pid , NULL , thread_handler , NULL);
            pthread_detach(pid);
        }
        i ++;
    }
    return 0;
}
```
### read函数的返回值
- `read` 函数的返回值:
  1. `> 0`  实际读取到的字符
  2. `= 0`  已经读取到了结果
  3. `-1`  需要进一步判断 `errno`的值:
     1. `errno = EAGAIN or errno = EWOULDBLOCK`: 设置了非阻塞法嗯时读,没有数据到到
     2. `errno = EINTR` 慢速系统调用,中断
     3. `errno = ECONNRESET` 表示连接被重置,需要重新建立连接
     4. `errno = 其他情况`  发生异常

## 多路IO转接服务器(多路IO复用)
- 客户端和服务器端建立连接的三种方式:
  - 阻塞(比如调用`Accept`函数阻塞等待客户端申请与服务器端建立连接)
  - 非阻塞式忙轮询:相当于服务器端过一段时间监听一下客户端的状态,等待客户端的连接
  - 响应式(也叫做**多路`IO`转接**): 表示客户端主动和服务器端建立连接,服务器不用等待客户端
- 之后的`select` , `poll` 还有 `epoll` 都是使用响应式的方式
- 响应式的实现方式(`select`):
![alt text](<../img/image copy 10.png>)
- 分析以下服务器端和客户端利用 `select` 建立连接的过程:
  - 首先`server`服务器调用`Socket`函数和`Bind`还有`Listen`函数绑定对应的参数之后把得到的`listenfd`交给`select`
  - 当有客户端需要连接服务器的时候,首先利用`select`的`listenfd`建立连接
  - 当有客户端和`select`连接的时候,此时`select`会通知`server`,此时`server`服务器就会调用`Accept`函数获取`connfd`之后转交给`select`和客户端进行数据的交换
### select 函数
- 作用: 完成多路`IO`转接
- 头文件: `#include <sys/select.h>`
- 函数原型如下:
```c
int select(int nfds, fd_set *_Nullable restrict readfds,
                  fd_set *_Nullable restrict writefds,
                  fd_set *_Nullable restrict exceptfds,
                  struct timeval *_Nullable restrict timeout);
```
- 参数:
  - `nfds`: 表示`select`管理的最大的一个文件描述符的最大值 `+ 1`(底层会利用循环遍历文件描述符)
  - `readfds`,`writefds`,`exceptfds` 都是传入传出参数
  - `timeout`: 表示等待时长
- 类型: `fd_set` 表示一种集合(本质就是一个位图),`readfds`,`writefds`,`exceptfds` 表示三种不同的事件,反别表示读事件,写事件和异常事件,意思就是监听某一个文件集合(比如`readfds = 4 5 writefds = 5 6  exceptfds = 7 8 ` 表示监听`4`号和`5`号的读事件,监听`5`号和`6`号的写事件,还有`7`号和`8`号的异常事件)
- 但是由于这三个参数都是传入传出参数,传入的意义: 需要监听相应事件的文件描述符号集合,传出的意义: 被监听的文件描述符号集合中发生了相应事件的文件描述符组成的集合
- `timeout`: 表示过期事件,如果传入一个`NULL`表示阻塞状态,`0`表示非阻塞状态(轮询状态)
- 返回值:
  - 成功返回三个结合中的文件描述符号的总个数,失败返回`-1`设置`errorno`(`0`有可能是在文件描述符的状态改变之前超出过期时间)
#### 对于fd_set的操作函数
- 作用: 操作`fd_set`(本质上就是位图)
- 函数原型:
```c
void FD_CLR(int fd, fd_set *set);
int  FD_ISSET(int fd, fd_set *set);
void FD_SET(int fd, fd_set *set);
void FD_ZERO(fd_set *set);
```
- `FD_CLR`: 表示把某一个`fd`置为`0`(表示把某一个`fd`从监听列表中去除,应用场景比如客户端关闭套接字(`read`返回值为 `0`))
- `FD_ISSET`: 表示判断`fd`是否在某一个位图中
- `FD_SET`: 表示添加`fd`到这一个位图中
- `FD_ZERO`: 表示把位图中的为都置为`0`
- 总结一下`select`函数的参数:
  - `nfds`: 监听到的所有文件描述符中,最大的文件描述符
  - `readfds`: 读文件描述符监听集合 传入传出参数
  - `writefds`: 写文件描述符监听集合 传入传出参数,一般设置为`NULL`
  - `exceptfds`: 异常文件描述符监听集合  传入传出结合 `NULL`
  - `timeout`:
    - `> 0`: 设置监听超时时长
    - `NULL`: 阻塞监听
    - `0`: 非阻塞监听,轮询
- 返回值：
  - `> 0`: 所有监听集合(`3`个)中,满足对应事件的总数
  - `0`: (超出过期时间)没有满足条件的文件描述符
  - `-1`: 表示发生异常
#### select 实现多路IO转接思路
- 思路分析:
  1. 利用`socket()`创建`listenfd`
  2. 调用`bind()`绑定`IP + port`
  3. 调用`listen()`设置最大连接数量
  4. 创建读监听集合
  5. `FD_ZERO(&rset)`清空读监听集合
  6. `FD_SET(lfd , &set)` 把`listenfd`添加到集合中
  7. **调用`select`监听文件描述符集合(`readfd`)对应的事件(过程中`rset`会发生改变只会得到发生了对应事件的文件描述符号,所以需要使用`allset`记录所有的文件描述符号)**
  8. **判断文件描述符号监听列表中是否存在`listenfd`**
  9. **如果存在`listenfd`,那么就需要把调用`accept`得到`cfd`,同时可以把`cfd`添加到集合中**
  10. 循环遍历得到发生了读取事件的文件描述符,向发生了读文件描述符号(表示**可读**)中读出数据同时进行业务操作写回去即可(其实真实的网络应用场景中,还是需要效仿`epoll`反应堆模型,判断是否可读)
- 可以设置一个变量专门用于记录文件描述符号的最大值,可以不断更新最大文件描述符
- 利用`select`实现多路`IO`转接:
```c
#include "wrap.h"
#include<sys/select.h>
#include<ctype.h>
#define SERVER_PORT 10086
int main()
{
    // 利用 select 实现 IO 多路转接
    // 1. 利用 Socket 获取 lfd
    int lfd , cfd , n;
    lfd = Socket(AF_INET , SOCK_STREAM , 0);
    // 2. 利用 Bind 绑定 端口和 IP
    struct sockaddr_in server_addr;
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(SERVER_PORT);
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    Bind(lfd , (struct sockaddr*)&server_addr , sizeof(server_addr));
    // 3. 利用 Listen 设置最大连接数量
    Listen(lfd , 128);
    // 4. 交给 select 管理 lfd
    int max_fd = lfd; // 表示最大的文件描述符号
    fd_set rset , allset; // allset 用于记录所有需要监听的文件描述符号,rset作为函数参数
    FD_ZERO(&allset);
    FD_SET(lfd , &allset);
    int ret; // 记录 accept结果
    struct sockaddr_in client_addr;
    socklen_t client_addr_len = sizeof(client_addr);
    char buf[BUFSIZ] , client_IP[BUFSIZ];
    printf("等待客户端连接... \n");
    while(1){  // 循环监听
        rset = allset;  // 每一次赋值
        ret = select(max_fd + 1 , &rset , NULL , NULL , NULL);
        // 开始判断
        if(ret > 0){
            if(FD_ISSET(lfd , &rset)){
                // 表示监听到客户端连接
                cfd = Accept(lfd , (struct sockaddr*)&client_addr , &client_addr_len);
                if(cfd > max_fd) max_fd = cfd;
                // 记录最大的文件描述符号个数
                // 打印信息
                printf("连接到客户端: %s:%d \n" , inet_ntop(AF_INET , (void*)&(client_addr.sin_addr.s_addr) , client_IP , client_addr_len) , ntohs(client_addr.sin_port));
                FD_SET(cfd , &allset);
                if(--ret == 0){
                    continue; // 表示此时 lfd 还是可以读取所以需要继续执行后面的操作,后面的for循环可以不用操作
                }
            }
            // 开始判断其他文件描述符号
            for(int i = lfd + 1 ; i <= max_fd ; i ++){
                if(FD_ISSET(i , &rset)){
                    // 表示监听到事件
                    n = read(i , buf , sizeof(buf));
                    if(n > 0){
                        for(int j = 0 ; j < n ; j ++){
                            buf[j] = toupper(buf[j]);
                        }
                        write(i , buf , n);
                    } else if(n == 0){  // 表示客户端关闭
                        close(i);
                        FD_CLR(i , &allset);
                    }
                }
            }
        } else if(ret == -1){
            perror("select failed !");
            exit(1);
        }
    }   
    close(lfd);
}
```
#### select优缺点
- 缺点:
  - 如果文件描述符的跨度比较大就会导致使用轮询的方式会浪费比较多的时间
  - 监听上限受到文件描述符最大值的限定
  - 检验满足条件的`id`,自己添加业务逻辑提高小,提高了编码难度
- 优点:
  - 唯一一个可以跨平台的多路`IO`转接方式
- 可以自定义数组(如果可以使用`vector`更好)来改善`select`轮询的缺点
- 小知识点: `FD_SETSIZE`表示文件描述符最大值,就是 `1024`
- 改进代码如下:
```c
#include"wrap.h"
#include<sys/select.h>
#include<ctype.h>
#define SERVER_PORT 10088
int main()
{
    // 使用 select 完成多路 IO 转接
    int lfd ,cfd , max_fd , maxi = -1 , sockfd;
    int clients[FD_SETSIZE]; // 表示最大长度 1024
    for(int i = 0 ; i < FD_SETSIZE ; i ++){
        clients[i] = -1;
    }
    lfd = Socket(AF_INET , SOCK_STREAM , 0);
    struct sockaddr_in server_addr;
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(SERVER_PORT);
    Bind(lfd , (struct sockaddr*)&server_addr , sizeof(server_addr));
    Listen(lfd , 128);
    fd_set rset , allset;  // 分别记录读的文件描述符号和所有的文件描述符
    FD_ZERO(&allset);
    FD_SET(lfd , &allset);
    max_fd = lfd;
    int ret;
    char buf[BUFSIZ] , client_IP[BUFSIZ];
    struct sockaddr_in client_addr;
    socklen_t client_addr_len;
    while(1){
        rset = allset;
        ret = select(max_fd + 1 , &rset , NULL , NULL, NULL); // 表示阻塞
        if(ret > 0){
            // 有信号发生改变
            if(FD_ISSET(lfd , &rset)){
                cfd = Accept(lfd , (struct sockaddr*)&client_addr , &client_addr_len);
                printf("客户端连接: %s:%d \n" ,inet_ntop(AF_INET , (void*)&(client_addr.sin_addr.s_addr) , buf , sizeof(buf)) , ntohs(client_addr.sin_port));
                if(cfd > max_fd){
                    max_fd = cfd;
                }
                // 加入到集合中
                FD_SET(cfd , &allset);
                // 此时可以进行初始化
                int i;
                for(i = 0 ; i <= FD_SETSIZE ; i ++){
                    if(clients[i] < 0){
                        clients[i] = cfd;
                        break;
                    }
                }
                if(i > maxi){
                    maxi = i; // 此时就可以记录最大值了
                }
                if(--ret == 0){
                    continue; // 表示只有 lfd 变化
                }
            } 

            // for(int i = lfd + 1 ; i <= max_fd ; i ++){
            //     if(FD_ISSET(i , &rset)){
            //         // 进行操作
            //         ret = read(i , buf , sizeof(buf));
            //         if(ret == 0){
            //             close(i);
            //             FD_CLR(i , &allset); // 表示结束了
            //         } else if(ret > 0){
            //             for(int j = 0 ; j < ret ; j ++){
            //                 buf[j] = toupper(buf[j]);
            //             }
            //             write(i , buf , ret);
            //         }
            //     }
            // }
            // 开始循环读取 clients[i]
            for(int j = 0 ; j <= maxi ; j ++){
                if((sockfd = clients[j]) < 0){
                    continue;
                }
                // 进行下一步判断
                if(FD_ISSET(sockfd , &rset)){
                    int n = read(sockfd , buf , sizeof(buf));
                    if(n == 0){
                        clients[j] = -1;
                        close(clients[j]);
                        FD_CLR(clients[j] , &allset);
                    } else if(n > 0){
                        for(int k = 0 ; k < n ; k ++){
                            buf[k] = toupper(buf[k]);
                        }
                        write(clients[j] , buf , n);
                    }

                    if(--ret == 0){
                        break; // 表示此时 lfd 没有发生变化此时只有一个 cfd 发生了变化那么处理完这一个cfd就可以了
                    }
                }
            }
        } else if(ret == -1){
            perror("select failed !");
            exit(1);
        }
    }
}
```
- 注意为什么上面还是需要判断`ret`这是由于文件描述符号处理之后检查是否还有没有处理的文件描述符,如果没有直接就可以退出了
### poll函数
- 作用: 完成多路`IO`转接(多路`IO`复用)
- 头文件: `<poll.h>`
- 函数原型:
```c
int poll(struct pollfd *fds, nfds_t nfds, int timeout);
```
- 其中`struct pollfd`结构体如下:
```c
  struct pollfd {
               int   fd;         /* file descriptor */
               short events;     /* requested events */
               short revents;    /* returned events */
           };
```
- 上面的成员分别表示:
  - `fd` 表示需要监听的文件描述符
  - `events` 表示事件类型(可以传入`POLLIN` , `POLLOUT` , `POLLERR`)
  - `revents` 表示传出的事件类型(参数和上面一样)(传入的时候可以给 `0` , 如果满足对应事件,返回非`0`(也就是上面的三种宏定义))
- 参数:
  - `fds`: 监听的文件描述符数组
  - `nfds`: 表示监听数组的实际有效的监听个数
  - `timeout`: 表示超时时长(单位就是毫秒):
    - `-1` 表示阻塞等待
    - `0`  表示不会阻塞线程,直接返回
    - `> 0`  表示指定等待的毫秒数,如果当前系统事件精度不够毫秒,就向上取值
- 返回值:
  - 返回满足对应监听事件的文件描述符总个数
#### poll函数的工作过程
- 和`select`函数的工作原理一模一样,不同的就是监听事件的初始化方式不同,在`poll`函数中需要定义一个数组来存放监听函数,存放完成之后循环读取并且从数组中取出监听元素即可,相当于`select`版本加上了一个数组
- 初始化过程如下:
![alt text](../img/Screenshot_20240901_105806_tv.danmaku.bilibilihd.jpg)
#### 利用poll函数实现多路IO转接
- 小知识： `INET_ADDRSTRLEN`的大小就是 `16` 
- 其实`poll`就是加上了数组的`select`(突破了文件描述符上限)
- `read` 函数的返回值:
  1. `> 0`  实际读取到的字符
  2. `= 0`  已经读取到了结果
  3. `-1`  需要进一步判断 `errno`的值 :
     1. `errno = EAGAIN or errno = EWOULDBLOCK`: 设置了非阻塞法嗯时读,没有数据到到
     2. `errno = EINTR` 慢速系统调用,中断
     3. `errno = ECONNRSET`  表示连接重置,需要关闭连接
```c
#include "wrap.h"
#include <poll.h>
#include<ctype.h>
#define SERVER_PORT 10089
int main()
{
    // 利用 poll 函数实现多路IO转接
    int lfd , cfd , count = 1 , maxi , ret , sockfd;
    struct pollfd pollfds[1024];
    lfd = Socket(AF_INET , SOCK_STREAM , 0);
    struct sockaddr_in server_addr;
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(SERVER_PORT);
    Bind(lfd , (struct sockaddr*)&server_addr , sizeof(server_addr));
    Listen(lfd , 128);
    // 进行 pollfds 的初始化
    for(int i = 0 ; i < 1024 ; i ++){
        pollfds[i].fd = -1; 
    }
    // 初始化
    pollfds[0].fd = lfd;
    pollfds[0].events = POLLIN;
    pollfds[0].revents = 0;  // 初始化为 0
    struct sockaddr_in client_addr;
    socklen_t client_addr_len = sizeof(client_addr);
    char buf[BUFSIZ] , client_IP[BUFSIZ];
    while(1){
        // 调用 poll函数
        ret = poll(pollfds , count , -1);
        
        // 首先判断 lfd 的事件
        if(pollfds[0].revents & POLLIN){
            // 此时就可以 Accept 了 
            cfd = Accept(lfd , (struct sockaddr*)&client_addr , &client_addr_len);
            printf("客户端连接: %s:%d \n" , inet_ntop(AF_INET , (void*)&(client_addr.sin_addr.s_addr),client_IP, sizeof(client_IP)) , ntohs(client_addr.sin_port));
            // 找到可以插入的位置
            int i;
            for(i = 0 ; i < 1024 ; i ++){
                if(pollfds[i].fd < 0){
                    pollfds[i].fd = cfd;
                    pollfds[i].events = POLLIN;
                    pollfds[i].revents = 0;
                    break;
                }
            }
            if(i > maxi){
                maxi = i;
            }
            count ++;
            if(--ret == 0){
                continue;
            }
        }
        // 开始进行一个遍历
        for(int j = 0 ; j <= maxi ; j ++){
            if((sockfd = pollfds[j].fd) < 0){
                continue;
            }

            if(pollfds[j].revents & POLLIN){
                // 此时就可以进行响应的操作了
                int n = read(sockfd , buf , sizeof(buf));
                if(n > 0){
                    // 进行相应的操作
                    for(int k = 0 ; k < n ; k ++){
                        buf[k] = toupper(buf[k]);
                    }
                    write(sockfd , buf ,n);
                } else if(n == 0){
                    // 关闭
                    pollfds[j].fd = -1;
                } else if(n == -1){
                    if(errno == ECONNRESET){
                        // 表示连接被重置
                        pollfds[j].fd = -1;
                        close(sockfd);
                    }
                }
                if(--ret == 0){
                    break; // 处理完毕
                }
            }
        }

    }
}
```
#### poll的优缺点
- 优点:
  - 自带数组结构,可以把监听事件集合和返回事件集合分离
  - 可以突破监听上限
- 缺点:
  - 不可以跨平台,只能在`Linux`中使用
  - 无法直接定位直接满足监听事件的文件描述符,需要使用轮询的方式定位
#### 突破1024文件描述符设置
- 利用: `cat /proc/sys/fs/file-max` 命令可以查看当前计算机可以打开的文件数量
- `ulimit -a`  可以查看当前用户下的进程,默认打开文件描述符的个数,缺省为 `1024`(默认)
- 修改`/etc/security/limits.conf`文件
- 填写`soft`和`hard`的值即可:
```c
*               soft    nofile          3000 // 默认值
*               hard    nofile          20000 // 修改值上限
```
注意只有`poll`和`epoll`可以突破`1024`文件描述符上限,`select`函数不可以
### epoll相关函数
#### epoll_create
- 作用: 打开一个 `epoll` 文件描述符(`epoll`本质其实就是一个红黑树)
- 函数原型: 
```c
int epoll_create(int size);
```
- 参数:
  - `size`: 创建的红黑树的监听节点数量(但是仅仅时对于内核的一个建议,并不是强制的)
  - 返回值：
    - 成功的话返回一个指向红黑树根节点的文件描述符
    - 失败返回 `-1`
#### epoll_ctl函数
- 作用: 控制红黑树
- 函数原型:
```c
int epoll_ctl(int epfd, int op, int fd,
                     struct epoll_event *_Nullable event);
```
- `struct epoll_event`结构体如下:
```c
   struct epoll_event {
           uint32_t      events;  /* 事件 */
           epoll_data_t  data;    /* 用到的数据变量 */
       };
```
- `epoll_data_t`如下:
- 联合体的概念可以参考: https://blog.csdn.net/mooneve/article/details/92703036
```c
  union epoll_data {
           void     *ptr;
           int       fd;
           uint32_t  u32;
           uint64_t  u64;
       };

       typedef union epoll_data  epoll_data_t;
```
- 参数:
  - `epfd`: `epoll`对应的文件描述符号
  - `op`: 表示对于红黑树的操作类型,可取值如下:
    - `EPOLL_CTL_ADD`  添加`fd`到监听红黑树
    - `EPOLL_CTL_MOD`  修改`fd`在监听红黑树上的监听事件
    - `EPOLL_CTL_DEL`  将`fd`从监听红黑树上摘下来(取消监听)
  - `event`(就只是一个结构体而已): 用于描述事件,成员如下:
    - `events`: 可取值为`EPOLLIN` , `EPOLLOUT` , `EPOLLERR`等
    - `data`: 是一个联合体:
      - `fd`: 表示对应监听事件的`fd`
      - `void* pstr`
      - `unit32_t`(不用)
      - `uint64_t`(不用)
- 返回值：
  - 成功返回`0`
  - 失败返回`-1`设置`errno`
#### epoll_wait函数
- 作用: 阻塞监听
- 函数原型:
```c
int epoll_wait(int epfd, struct epoll_event *events,
                      int maxevents, int timeout);
```
- 参数:
  - `epfd`: 表示`epoll`的文件描述符
  - `events`: 数组,传出参数(需要监听的文件描述符号可以使用`epoll_ctl`指定),传出的都是满足条件的(监听到事件的)
  - `maxevents`: 表示数组元素的总个数,类似于`read`函数中`buf`的长度
  - `timeout`: 
    - `-1` 阻塞
    - `0`  非阻塞
    - `> 0`  设置超时事件
- 返回值:
  - `> 0`  满足监听的总个数(循环的遍历上限(数组中的都是满足条件的个数))
  - `0`    没有`fd`满足监听事件
  - `-1`   表示错误情况 
#### 利用epoll实现多路IO复用
- 实现方式如下:
- 注意`epoll_ctl`中需要传入的结构体充当传入传出参数,所以需要指定文件描述符
```c
#include "wrap.h"
#include<ctype.h>
#include<sys/epoll.h>
#define SERVER_PORT 10090
int main()
{
    int lfd , cfd , epollfd , ret , sockfd;
    struct epoll_event ep_events[BUFSIZ];  // 就是一个传出参数
    char buf[BUFSIZ] , client_IP[BUFSIZ];
    lfd = Socket(AF_INET , SOCK_STREAM , 0);
    struct sockaddr_in server_addr;
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(SERVER_PORT);
    Bind(lfd , (struct sockaddr*)&server_addr , sizeof(server_addr));
    Listen(lfd , 128);
    // 获取 epollfd
    epollfd = epoll_create(BUFSIZ);
    // 把 lfd 添加到 epoll中
    struct epoll_event  ep_event;
    ep_event.events = EPOLLIN;
    ep_event.data.fd = lfd;
    epoll_ctl(epollfd , EPOLL_CTL_ADD , lfd , &ep_event);
    struct sockaddr_in client_addr;
    socklen_t client_addr_len = sizeof(client_addr);
    printf("等待客户端连接 ...\n");
    while(1){
        ret = epoll_wait(epollfd , ep_events , BUFSIZ , -1);
        if(ret > 0){
            // 首先判断 ep_events
            for(int i = 0 ; i < ret ; i ++){
                // 如果是 lfd
                if((sockfd = ep_events[i].data.fd) == lfd ){
                    // 调用 Accept函数
                    cfd = Accept(lfd , (struct sockaddr*)&client_addr , &client_addr_len);
                    printf("连接到客户端: %s:%d \n" , inet_ntop(AF_INET , (void*)&(client_addr.sin_addr.s_addr) , client_IP , sizeof(client_IP)) , ntohs(client_addr.sin_port));
                    // 添加到 epoll
                    ep_event.events = EPOLLIN;
                    ep_event.data.fd = cfd;
                    epoll_ctl(epollfd , EPOLL_CTL_ADD , cfd , &ep_event);
                } else {
                    // 业务逻辑操作
                    int n = read(sockfd , buf , sizeof(buf));
                    if(n > 0){
                        for(int j = 0 ; j < n ; j ++){
                            buf[j] = toupper(buf[j]);
                        }
                        write(sockfd , buf , n);
                    } else if(n == 0){
                        // 关闭
                        close(sockfd);
                        epoll_ctl(epollfd , EPOLL_CTL_DEL , sockfd , NULL);
                    } else if(n == -1){
                        perror("read from socket failed !");
                        if(errno == ECONNRESET){
                            close(sockfd);
                            epoll_ctl(epollfd , EPOLL_CTL_DEL , sockfd , NULL);
                        }
                    }

                }
            }
        }
    } 
}
```
- `select`和`poll`的增强版本,它可以显著提高,它可以显著提高在大量并发连接中只有少量活跃的情况下系统`CPU`利用率,这是由于它会复用文件描述符集合来传递结果而不是迫使开发者每一次等待事件之前都必须重新准备需要被侦听的文件描述符集合,另外一点原因就是在获取事件的时候,它无需遍历整个被侦听的描述符表,只需要遍历那些被内核`IO`一部唤醒而加入`Ready`队列的文件描述符号表集合即可
### epoll中事件模型
- `epoll`中的事件模型:
  - `ET`模型:
    - 边沿触发
  - `LT`模型(默认):
    - 水平触发
- 边沿触发: 缓冲区中剩余的数据不会导致`epoll_wait`触发
- 水平触发: 缓冲区中剩余的数据会导致`epoll_wait`触发
- 设置边沿触发(`ET`模式的方式: 在结构体的实现设置的时候设置 `event = 事件类型 | EPOLLET`)
- 注意使用`epoll`是监视文件描述符,所有不一定需要监控`socket`,还可以监听其他文件描述符
- 演示代码如下:
```c
#include<stdio.h>
#include<stdlib.h>
#include<unistd.h>
#include<sys/epoll.h>
#include<fcntl.h>
#define MAX_LINE 10
int main()
{
    // 验证 epoll 的 ET 模式
    int pfds[2];
    pipe(pfds);
    char buf[MAX_LINE], ch = 'a';
    struct epoll_event ep_events[MAX_LINE];
    int pid = fork();
    if(pid == 0){
        // 子进程
        close(pfds[0]);
        while(1){
            int i ;
            for(i = 0 ; i < MAX_LINE / 2 ; i ++){
                buf[i] = ch;
            }
            buf[MAX_LINE / 2  - 1] = '\n';
            ch ++;
            for( ; i < MAX_LINE ; i ++){
                buf[i] = ch;
            }
            buf[MAX_LINE - 1] = '\n';
            ch ++;
            write(pfds[1] , buf , MAX_LINE);
            sleep(5);
        }

    } else if (pid > 0){
        // 父进程
        close(pfds[1]);
        int efd = epoll_create(MAX_LINE);
        struct epoll_event ep_event;
        ep_event.events = EPOLLIN;
        // ep_event.events = EPOLLIN | EPOLLET;
        ep_event.data.fd = pfds[0];
        epoll_ctl(efd , EPOLL_CTL_ADD , pfds[0] ,&ep_event);
        char read_buf[MAX_LINE];
        while(1){
            int ret = epoll_wait(efd , ep_events , MAX_LINE , -1);
            if(ret > 0){
                int n = read(pfds[0] , read_buf , MAX_LINE / 2);
                write(STDOUT_FILENO , read_buf , n);
            }
        }

    }
}
```
#### 网络中的ET和LT模式
- 性质还是和上面一样
- 设置方式:
```c
struct epoll_event ep_event;
ep_event.events = EPOLLIN | EPOLLET;
ep_event.data.fd = connfd;
```
#### epoll的ET非阻塞模式
- `LT`: 是缺省的工作方式,同时支持`block`和`no-block`,这一种做法中,内核告诉你一个文件描述符是否就绪了,然后你可以对于这一个就绪的`fd`进行`IO`操作,如果不进行任何操作,内核还是会继续通知你的,所以这一种模式编程出现错误可能性比较小,传统的`select/poll`都是这一种模型的代表
- `ET`: 是高速工作方式,只是支持`no-block socket`,在这种模式中,对描述符从未就绪变为就绪时,内核通过`epoll`告诉你,然后它会假设你知道文件描述符已经就绪,并且不会在为那个文件描述符发送更多的就绪通知,请注意,如果一直不对于这一个`fd`做`IO`操作(从而导致它再次变成未就绪),内核不会发送更多的通知
- **注意如果`ET`使用阻塞模式,那么比如如果读取套接字的时候读取的字节个数小于指定的字节个数,此时由于不会自动触发`epoll_wait`函数就会不断阻塞等待,由于`read`阻塞所以无法到达`epoll_wait`,所以就会处于一个死循环的状态(但是`ET`必须设置非阻塞模式)**
- 可以使用 `fcntl` 函数设置非阻塞
- 比如设置非阻塞状态:
```c
flag = fcntl(connfd , F_GETFL);
flag |= O_NOBLOCK;
fcntl(connfd , F_SETFL , flag);
```
- `epoll`的实践:
```c
struct epoll_event event;
event.events = EPOLLIN | EPOLLET;
event.data.fd = cfd;
epoll_ctl(efd , EPOLL_CTL_ADD , cfd , &event);
flag = fcntl(cfd , F_GETFL);
flag |= O_NOBLOCK;
fcntl(cfd , F_SETFL , flag);
```
#### epoll特点
- 优点:
  - 高效,可以突破`1024`限制
- 缺点:
  - 不可跨平台,`Linux`
#### 对比ET和LT
- `ET`模式: 应用于只用读取文件的一部分内容
- `LT`模式: 应用于需要读取文件的全部部分
### epoll反应堆模型
- `epoll`反应堆模型的大体流程如下:
![alt text](../img/Screenshot_20240901_214623_tv.danmaku.bilibilihd.jpg)
- **利用 `epoll ET`模式 + 非阻塞 + `void* ptr`**
- 由于`epoll_data`是一个联合体,所以不可以有两个共存的成员,利用`void* ptr` 可以携带`fd`和回调函数,比如定义一个结构体,结构体的成员中有回调函数和文件描述符
- `epoll`反应堆中不但需要监听读事件还需要监听写事件
- `epoll`反应堆中的`main`逻辑:
  - 利用`epoll_wait`初始化
  - 绑定端口,`IP`等
  - ...
  - 判断读写操作,调用相应的回调函数
- 小知识: 宏定义: `__func__` 表示函数名称
- `lfd`和`cfd`回调函数的绑定: 在`initlistensocket`函数中做了初始化`lfd`的工作,另外还把`lfd`绑定了回调函数`acceptconn`函数,并且把`lfd`放在了数组最后一个参数的位置(这一个回调函数在读取的时候就会被调用)
- 在`acceptconn`函数调用`accept`函数生成`cfd`并且为`cfd`绑定了回调函数(`recvdata()`)
- `eventset`函数和`eventadd`函数:
  - `eventset`函数: 设置回调函数(`lfd` --> `acceptconn` , `cfd` --> `recvdata()`)
  - `eventadd`函数中:
    - 将一个`fd`添加到红黑树中,监听红黑树,设置监听`read`事件,还是监听写事件
- `recv`函数相当于网络编程中的`read`函数   `send`函数相当于网络编程中的`write`函数
- `epoll_wait`调用之后,如果是读实现,那么就会回调读的的回调函数,这一个回调函数中完成的事情就是首先把数据读取到结构体的缓冲区中,并且把该节点从`epoll`中摘除,并且绑定读事件,如果再次触发读事件,那么就会触发读的回调函数,读的回调函数中首先回写到对应的函数中并且把该`fd`从红黑书中摘下来,并且重新绑定写事件即可,注意改变结构体的状态
- 检测超时的机制方式就是不断检验超时超过`60s`的文件描述符号并且把这一个关闭即可
- 这里为什么回调函数的第三个参数还是结构体本身,这是由于在绑定回调函数的时候,回调函数中还需要这个参数本身来绑定其他的回调函数
#### epoll补充内容
- 可以使用`man epoll`可以查看`epoll`相关的例程
- `epoll`反应堆中的读写回调判断其实判断了两次,就是验证此时传出的是读实现并且需要监听的就是读函数,可以自己查看源代码
#### ctags
- 利用`ctags ./* -R`可以生成 `tags`文件
- 之后可以进行如下操作:
  - `ctrl + ]`  光标放置在调用函数上,跳转到函数定义位置
  - `ctrl + t`  返回跳转位置之前
  - `ctrl + o`  屏幕左边列出未见了列表,再次关闭
  - `F4`        右边列出函数列表
## 线程池
- 线程池中的各种组件如下:
![alt text](../img/Screenshot_20240903_101345_tv.danmaku.bilibilihd.jpg)
### 线程池模型原理
- 每一次进行线程的创建和线程的销毁的开销比较大,所以可以使用线程池的方式
- 线程池只是一个虚拟的概念,其实并不存在这样一个概念,可以理解成线程的聚集之处,可以利用条件变量进行线程池的阻塞(这里的条件变量可以设置为任务队列不为`NULL`,当条件变量阻塞结束的时候就可以取出线程处理任务了)
- 线程池的参数包含初始线程的数量,最大线程的数量还有忙碌线程的数量以及活跃线程的数量,当忙碌线程的数量逐渐增加的时候,就可以对于线程池进行扩容,当忙碌的线程数量比较小的时候,就可以对于线程池进行缩小容量的操作
- 另外需要维护一个管理者线程,这一个管理者线程对于线程池中的线程进行一系列的操作(包含扩容缩容等)
#### 线程池描述结构体
- 线程池描述结构体如下:
```c
#include<stdio.h>
#include<unistd.h>
#include<stdlib.h>
#include<pthread.h>
// 任务队列中的任务
typedef struct threadpool_task_t{
    void* (*function)(void*);  // 表示任务函数
    void* arg;   // 表示参数
}threadpool_task_t;
// 线程池描述结构体
struct threadpool_t {
    pthread_mutex_t lock;         // 用于锁住结构体本身
    pthread_mutex_t thread_counter;  // 记录忙碌状态下的线程个数的锁

    pthread_cond_t queue_not_full;  // 当任务队列为满的时候,添加到任务队列中的线程阻塞,等待这一个条件变量(阻塞服务器)    反面就是满足条件
    pthread_cond_t queue_not_empty; // 当任务队列不为空的时候,通知等待任务的线程(阻塞线程池中的线程)               反面就是满足条件

    pthread_t* threads;  // 存放线程池中每一个线程的tid,数组
    pthread_t adjust_tid; // 存放管理线程 tid
    threadpool_task_t* task_queue;   // 任务队列(数组首地址)
 
    int min_thr_num;  // 线程池最小线程数量
    int max_thr_num;  // 线程池最大线程数量
    int live_thr_num; // 当前存活状态线程个数
    int busy_thr_num;  // 忙状态的线程个数
    int wait_exit_thr_num; // 需要销毁的线程个数

    int queue_front;  // task_queue 队头下标(环形队列)
    int queue_rear;   // task_queue 队尾下标
    int queue_size;  // task_queue 队列中的实际任务数量
    int queue_max_size;  // task_queue 中可以容纳的任务数上限

    int shutdown;   // 标志位,线程池使用状态,true或者false
};
```
- 使用线程池的方法:
  - **首先调用创建线程池的方法创建线程池**
  - **之后调用把任务交给线程池**
  - **最后调用销毁线程池的方法销毁线程池**
- 一个小的知识点,可以使用`do...while(0)`替代`goto`,可以直接`break`出去
#### 创建线程池
- 创建线程池结构体指针
- 初始化线程池结构体(`N`个成员变量)
- 创建`N`个任务线程
- 创建`1`个管理线程
- 失败的时候,销毁开辟的所有空间
#### 回调函数
- 进入子线程回调函数
- 接受参数,把`void* arg` --> `pool 结构体`
- 加锁 --> `lock` --> 整个结构体的锁
- 判断条件变量 --> `wait`
#### 管理者线程
- 进入管理者线程回调函数
- 接受参数: `void* arg` --> `pool`结构体
- 加锁 --> `lock` --> 整个结构体锁
- 获取管理线程池需要使用的变量 , `task_num` , `live_num` , `busy_num`
- 根据既定算法,使用上述三个变量,判断是否应该创建,销毁线程池中指定步长的线程
#### threadpool_add函数
- 作用: 添加任务到任务队列中
- 初始化任务队列结构体成员,回调函数`function`,`arg`
- 利用环形队列机制,实现添加任务,借助队尾指针移动实现(环形队列,你懂得)
- 唤醒阻塞在条件变量上的线程
- 解锁
#### 子线程处理任务
- 在`pthread_cond_wait`函数管理的区域中
- 获取任务处理回调函数和参数
- 利用环形队列机制,实现处理任务,借助队头指针移动实现
- 环形阻塞在环境变量上的`server`
- 解锁
- 加锁
- 修改忙线程数量++
- 解锁
- 执行处理任务的线程
- 加锁
- 该忙线程 --
- 解锁
#### threadpool_destory函数
- 首先把线程池设置为关闭状态
- 销毁管理者线程
- 之后唤醒所有线程(可以使用`pthread_cond_brocast`方法虽然唤醒所有线程但是只有一个线程可以拿到锁,拿到锁的线程由于条件不满足就会执行退出函数从而退出)
#### 管理者线程
- 根据默认的步长进行创建线程和销毁线程:
- 创建线程就可以使用`pthread_create`函数进行线程的创建(回调任务线程函数)
- 销毁线程还是可以使用`pthread_cond_brocast`唤醒线程执行线程退出函数
## UDP协议
### TCP通信和UDP通信各自的优缺点
- `TCP`: 面向连接的,可靠数据包传输(对于不稳定的网络层,采取完全弥补的通信方式,丢包重传,但是还是可能有丢包风险)
    - 优点: 稳定
      - 数据流量稳定,速度稳定,顺序
    - 缺点: 
      - 传输速度满,传输的效率比较低,开销比较大
    - 使用场景: 数据的完整型要求比较高,不追求效率,大文件传输,文件传递
- `UDP`: 无连接,不可靠的数据包传输(对于完全不稳定的网络层,采取完全不弥补的通信方式,默认还原网络状况)
  - 优点: 传输速度比较快,效率比较高,开销小
  - 缺点: 不稳定,数据流量,速度,顺序
  - 使用场景: 对于时效性要求比较高的场合,稳定性其次(比如游戏，视频会议等)
- 其实可以在应用层数据校验协议,弥补`udp`的不足
### UDP通信客户端和服务器端流程
- 由于没有连接,所以不需要`accept`和`connect`函数,同时也不需要连接数
- 注意`recv`和`send`智能用于`TCP`通信
- `server`:
  - 创建`socket()`,`lfd = Socket(AF_INET , SOCK_DGRAM(表示报式协议),0)`
  - `bind()`
  - `listen()`  可以省略
  - 不使用`read`函数,使用`recvfrom`替换
  - 不使用`write`函数,替换成`sendto`函数
  - 最后关闭: `close()`
- `client`:
  - `socket()`  `lfd = Socket(AF_INET , SOCK_DGRAM , 0)`
  - `sendto(服务器的地址结构,结构体大小)`函数
  - `recvfrom()`
  - 写到屏幕上
  - `close()`
#### recvfrom函数
- 作用: 从指定的`IP`地址的某一个端口接受数据
- 函数原型:
```c
       ssize_t recvfrom(int sockfd, void buf[restrict .len], size_t len,
                        int flags,
                        struct sockaddr *_Nullable restrict src_addr,
                        socklen_t *_Nullable restrict addrlen);

```
- 参数:
  - `sockfd`: `Socket`函数的返回值
  - `buf`: 缓冲区
  - `len`: 缓冲区大小
  - `flags`: 可以传递`0`表示读的作用
  - `src_addr`: 数据源的地址结构(传出参数)
  - `addrlen`: 数据源地址结构的大小(传入传出参数)
- 返回值:
  - 接收到的字节数量,错误返回`-1`(`errno`),`0`表示队端关闭
#### sendto函数
- 作用: 从指定的`IP`地址的某一个端口发送数据
- 函数原型:
```c
ssize_t sendto(int sockfd, const void buf[.len], size_t len, int flags,
                      const struct sockaddr *dest_addr, socklen_t addrlen);
```
- 参数:
  - `sockfd`: `Socket`函数的返回值
  - `buf`: 存储数据的缓冲区
  - `len`: 缓冲区容量
  - `flags`: 可以传递`0`表示写的作用
  - `dest_addr`: 传入参数,表示目标的地址结构
  - `addrlen`: 地址结构长度
- 返回值:
  - 成功返回: 成功写出数据字节数量,失败返回 `-1`
- 客户端:
```c
#include "wrap.h"
#define SERVER_PORT 10086
#define CLIENT_PORT 10089
int main()
{
    // 1. Socket()函数
    int lfd , ret;
    lfd = Socket(AF_INET , SOCK_DGRAM , 0);
    // 2. 准备服务器端地址
    struct sockaddr_in server_addr;
    inet_pton(AF_INET , "127.0.0.1" , &server_addr.sin_addr);
    server_addr.sin_port = htons(SERVER_PORT);
    server_addr.sin_family = AF_INET;
    // Bind(lfd , &server_addr , sizeof(server_addr));
    char client_IP[BUFSIZ];
    printf("server:%s:%d \n" , inet_ntop(AF_INET , (void*)&(server_addr.sin_addr.s_addr) , client_IP , sizeof(server_addr)) , ntohs(server_addr.sin_port));
    struct sockaddr_in client_addr;
    client_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    client_addr.sin_family = AF_INET;
    client_addr.sin_port = htons(CLIENT_PORT);
    Bind(lfd , (struct sockaddr*)&client_addr , sizeof(client_addr));
    // 3. 开始写数据并且监听
    char buf[BUFSIZ];
    while(1){
        scanf("%s" , buf);
        sendto(lfd , buf , strlen(buf) , 0 , (struct sockaddr*)&server_addr , sizeof(server_addr));
        // 回收结果
        ret = recvfrom(lfd , buf , sizeof(buf) , 0 , NULL , 0);
        if(ret == -1){
            perror("read from server failed !");
            exit(1);
        } else if(ret > 0){
            write(STDOUT_FILENO , buf , ret);
        }
    }
    close(lfd);
}
```
- 服务器端:
```c
#include "wrap.h"
#include<ctype.h>
#define SERVER_PORT 10086
int main()
{
    // 1. 获取 Socket
    int lfd , ret;
    lfd = Socket(AF_INET , SOCK_DGRAM , 0);
    // 2. 利用 Bind绑定地址结构
    struct sockaddr_in server_addr;
    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
    server_addr.sin_port = htons(SERVER_PORT);
    server_addr.sin_family = AF_INET;
    Bind(lfd , (struct sockaddr*)&server_addr , sizeof(server_addr));
    // 3. 利用 Listen设置最大监听数量,当然也可以不用设置
    // Listen(lfd , MAX_CONNECT);
    // 4. 循环调用接受函数接受
    char buf[BUFSIZ] , client_IP[BUFSIZ];
    struct sockaddr_in client_addr;
    socklen_t client_addr_len;
    while(1){
        ret = recvfrom(lfd , buf , sizeof(buf) , 0 , (struct sockaddr*)&client_addr , &client_addr_len);
        if(ret == -1){
            perror("recv from client failed !");
        }
        printf("ret = %d \n" , ret);
        printf("client: %s:%d \n" , inet_ntop(AF_INET , (void*)&(client_addr.sin_addr.s_addr) , client_IP , sizeof(buf)) , ntohs(client_addr.sin_port));
        for(int i = 0 ; i < ret ; i ++){
            buf[i] = toupper(buf[i]);
        }
        printf("%s",buf);
        // 写回去
        ret = sendto(lfd , buf , ret , 0 , (struct sockaddr*)&client_addr , sizeof(client_addr));
        if(ret == -1){
            perror("send to client failed !");
        }
    }
    close(lfd);
}
```
## 本地套接字
### 本地套接字和网络套接字比较
- `IPC`(进程之间的通信方式): `pipe`,`fifo`,`mmap`,信号,本地套接字(`domain`)(`CS`模型)
- 本地套接字和网络套接字不同之处:
  - `socket()` 参数 `(AF_UNIX/AF)LOCAL , SOCK_STREAM / SOCK_DGRAM ,  )`
  - `bind()` 使用的地址结构改变, `sockaddr_in --> sockaddr_un`
- 初始化方式:
```c
struct sockaddr_un srv_addr;
srv_addr.sun_family = AF_UNIX;
strcpy(srv_addr.sun_path , "路径");
len = 2(表示头部的地址类型) + strlen(srv_addr.sun_path); // 由于字符串的大小不同,所以需要注意
```
- 可以使用函数求解结构体中的成员相对于结构体的首地址的偏移量(这一个函数挺好用的):
```c
len = offsetof(struct sockaddr_un , sun_path) + strlen(un.sun_path);
```
- 为了保证`bind`可以成功,会创建一个`socket`,因此保证`bind`成功,通常在我们`bind`之前,需要使用`ulink(srv.socket)`使得他创建新的
- 套接字文件是伪文件,不占用磁盘空间
- `offsetof`函数原型如下:
```c
size_t offsetof(type, member);
```
- 客户端不依赖隐式地址绑定,并且应该在通信建立连接的过程中,创建并且初始化`2`个套接字文件
- 服务器端代码如下:
```c
#include "wrap.h"
#include<ctype.h>
#include <sys/un.h>
#define SERV_SOCKET "serv.socket"
int main()
{
    // 客户端通信
    int lfd , cfd , ret ,len;
    // 1. 利用 Socket 获取 lfd
    lfd = Socket(AF_UNIX , SOCK_STREAM , 0);
    // 2. 利用 Bind 绑定地址结构
    struct sockaddr_un server_addr;
    bzero(&server_addr , sizeof(server_addr));  // 表示清空地址空间
    server_addr.sun_family = AF_UNIX;
    strcpy(server_addr.sun_path , SERV_SOCKET);
    len = offsetof(struct sockaddr_un , sun_path) + strlen(server_addr.sun_path);
    unlink(SERV_SOCKET);
    Bind(lfd , (struct sockaddr*)&server_addr , len);
    Listen(lfd , 20);
    // 3. 利用 Accpet 进行接受
    char buf[BUFSIZ];
    struct sockaddr_un client_addr;
    len = sizeof(client_addr);
    cfd = Accept(lfd , (struct sockaddr*)&(client_addr) , (socklen_t*)&len);
    while(1){
        
        printf("cfd = %d \n" , cfd);
        if(cfd == -1){
            perror("Accept failed !");
        }
        ret = read(cfd , buf , sizeof(buf));
        printf("ret = %d \n" , ret);
        if(ret == -1){
            perror("read from cfd failed !");
        } else if(ret == 0){
            perror("cfd closed !");
            close(cfd);
        } else if(ret > 0){
            
            for(int i = 0 ; i < ret ; i ++){
                buf[i] = toupper(buf[i]);
            }
            printf("%s\n" , buf);
            write(cfd , buf , ret);
        }
    }
    close(lfd);
}
```
- 客户端代码:
```c
#include "wrap.h"
#include <stddef.h>
#include <sys/un.h>
#define SERV_SOCKET "serv.socket"
#define CLIE_SOCKET "clie.socket"
int main()
{
    // 1. 利用 Listen 获取 cfd 
    int cfd , lfd , ret;
    cfd = Socket(AF_UNIX , SOCK_STREAM , 0);
    // 2. 利用 Bind 绑定地址
    struct sockaddr_un client_addr , server_addr;
    bzero(&client_addr , sizeof(client_addr));
    bzero(&server_addr , sizeof(server_addr));
    client_addr.sun_family = AF_UNIX;
    server_addr.sun_family = AF_UNIX;
    strcpy(client_addr.sun_path , CLIE_SOCKET);
    strcpy(server_addr.sun_path , SERV_SOCKET);
    int client_addr_len = offsetof(struct sockaddr_un , sun_path) + strlen(client_addr.sun_path);
    int server_addr_len = offsetof(struct sockaddr_un , sun_path) + strlen(server_addr.sun_path);
    unlink(CLIE_SOCKET);
    Bind(cfd , (struct sockaddr*)&client_addr , client_addr_len);
    char buf[BUFSIZ];
    Connect(cfd , (struct sockaddr*)&server_addr , server_addr_len);
    while(1){
        scanf("%s" , buf);
        write(cfd , buf , strlen(buf));
        ret = read(cfd , buf , sizeof(buf));
        if(ret > 0){
            write(STDOUT_FILENO , buf , ret);
        }
    }
}
```
- 注意所有的长度都需要使用 `offsetof(结构名,属性名) + strlen(成员字符串)`
- 注意如果只是需要一对一的连接,把`Accpet`函数写在循环外面,否则就会阻塞连接(多进程多线程情况下写在里面可以)

# 机器学习
## 线性模型
### Logistic回归
- 首先回归问除了需要获取一个判别函数($f(x; \mathbf \omega) = {\mathbf \omega}^T {\mathbf x} + b$ ) 之外还需要确定一个决策函数$g(x)$ 用于把判别函数的结果映射到一个有效的类别上
- `Logistic`回归可以利用于解决二分类的问题,考虑后验概率:
$$
p(y = 1 | {\mathbf x}) = g(f({\mathbf x}; {\mathbf \omega})) 
$$
- `Logisitc`回归中使用`Logistic`函数作为激活函数,比如标签$y = 1$ 的后验概率为 
$$
p(y = 1 | x) = \sigma({\mathbf \omega}^{T}{\mathbf x}) = \frac{1}{1 + \exp(-{\mathbf \omega}^{T}{\mathbf x})} 
$$
- 这里的$\omega$ 增广权重矩阵 , $\mathbf x$ 是增广特征矩阵
- 从而可以得到:
$$
p(y = 0 | {\mathbf x}) = 1 - p(y = 1 | {\mathbf x}) 
$$
- 结合上面两个式子可以得到:
$$
{\mathbf \omega}^{T}{\mathbf x} = log{\frac{p(y = 1 | {\mathbf x})}{p(y = 0 | {\mathbf x})}}
$$
- 参数学习的过程中使用交叉熵函数作为损失函数并且利用梯队下降算法来优化参数
- 后验概率为:
$$
\widehat y^{(n)} = \sigma({\mathbf \omega}^{T}{\mathbf x}^{{n}})  
$$
- 所以可以得到:
$$
p_r(y^{n} = 1 | {\mathbf x}^{n}) = y^{(n)}  
$$
$$
p_r(y^{n} = 0 | {\mathbf x}^{n}) = 1- y^{(n)}
$$
![[Pasted image 20241111214717.png]]
### Softmax回归
